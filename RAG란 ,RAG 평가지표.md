# RAGëž€?, RAG í‰ê°€ì§€í‘œ

## RAGëž€? [RAG_paper](https://arxiv.org/abs/2005.11401) , [ì°¸ê³  ê¸€1](https://modulabs.co.kr/blog/retrieval-augmented-generation/) , [ì°¸ê³  ê¸€2](https://jeonsworld.github.io/NLP/rag/)

RAG(Retrieval-Augmented Generation)ëŠ” LLMì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì œì•ˆëœ ê¸°ìˆ ì´ë‹¤. LLMì€ ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ì „ í•™ìŠµí•˜ì—¬ ê°•ë ¥í•œ ì–¸ì–´ ì´í•´ ë° ìƒì„± ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìžˆì§€ë§Œ, í•™ìŠµ ë°ì´í„°ì— ì—†ëŠ” ìµœì‹  ì •ë³´ë‚˜ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹ì€ ì œê³µí•˜ê¸° ì–´ë µë‹¤ëŠ” ë‹¨ì ì´ ìžˆë‹¤. RAGëŠ” ì´ëŸ¬í•œ LLMì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ â€˜Retrievalâ€™ê³¼ â€˜Language generationâ€™ì„ ê²°í•©í•œ í”„ë ˆìž„ì›Œí¬ë‹¤. RAGì˜ ê¸°ë³¸ ì•„ì´ë””ì–´ëŠ” ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì§€ì‹ì„ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•˜ì—¬ í™œìš©í•˜ëŠ” ê²ƒì´ë‹¤.

RAGì˜ ë…¼ë¬¸ì—ì„œëŠ” â€œPre-trained language model (ex : LLM)ì€ factual knowledgeë¥¼ ë§¤ê°œë³€ìˆ˜ì— ì €ìž¥í•˜ê³  downstream NLP taskì— ëŒ€í•´ fine-tuningì„ ìˆ˜í–‰í•  ë•Œ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ì§€ë§Œ knowledgeì— ì ‘ê·¼í•˜ê³  ì •í™•í•˜ê²Œ ì¡°ìž‘í•˜ëŠ” ê²ƒì€ ì—¬ì „ížˆ ì œí•œë˜ì–´ ìžˆìœ¼ë¯€ë¡œÂ knowledge-intensiveÂ taskì— ëŒ€í•´ì„œëŠ” task-specific architecture(question answering or text summarization ë“±)ë³´ë‹¤ ì„±ëŠ¥ì´ ë–¨ì–´ì§„ë‹¤. (ì¦‰ LLMì€ ë²”ìš©ì„±ì€ ì¢‹ìœ¼ë‚˜ ê°ê°ì˜ taskì—ì„œëŠ” task-specific model ë³´ë‹¤ ì„±ëŠ¥ì´ ë–¨ì–´ì§) pre-trained ëª¨ë¸ê³¼ non-parametric memoryë¥¼ ê²°í•©í•œ RAG(Retrieval-Augmented Generation)ë¥¼ ì œì•ˆí•œë‹¤â€ê³  í•˜ì˜€ë‹¤.

- LLMì˜ ë‹¨ì 
    1. íŽ¸í–¥ì„± ë¬¸ì œ
        - í•™ìŠµ ë°ì´í„°ì— ë‚´ìž¬ëœ íŽ¸í–¥ì„±ì„ ê·¸ëŒ€ë¡œ ë°˜ì˜í•  ìˆ˜ ìžˆìŒ
        - ì„±ë³„, ì¸ì¢…, ì¢…êµ ë“±ì— ëŒ€í•œ ê³ ì •ê´€ë…ì´ë‚˜ ì°¨ë³„ì  í‘œí˜„ì„ ìƒì„±í•  ìœ„í—˜ ì¡´ìž¬
    2. ì‚¬ì‹¤ ê´€ê³„ ì˜¤ë¥˜ ê°€ëŠ¥ì„±
        - ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì§€ë§Œ, í•­ìƒ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ëŠ” ì•ŠìŒ
        - ìž˜ëª»ëœ ì •ë³´ë‚˜ í—ˆìœ„ ì •ë³´ë¥¼ ì§„ì‹¤ë¡œ ê°„ì£¼í•˜ê³  ì „íŒŒí•  ìˆ˜ ìžˆìŒ
    3. ë§¥ë½ ì´í•´ì˜ í•œê³„
        - ë¬¸ìž¥ ë‹¨ìœ„ì˜ ì´í•´ëŠ” ê°€ëŠ¥í•˜ì§€ë§Œ, ìž¥ë¬¸ì˜ ê¸€ì´ë‚˜ ë³µìž¡í•œ ë§¥ë½ íŒŒì•…ì€ ì–´ë ¤ìš¸ ìˆ˜ ìžˆìŒ
        - ì„¸ê³„ ì§€ì‹ê³¼ ìƒì‹ ì¶”ë¡  ëŠ¥ë ¥ì´ ë¶€ì¡±í•˜ì—¬ ì‹¬ì¸µì ì¸ ì´í•´ì— í•œê³„ ì¡´ìž¬
    4. ì¼ê´€ì„± ë¬¸ì œ
        - ë™ì¼í•œ ìž…ë ¥ì— ëŒ€í•´ ì¼ê´€ëœ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ì•Šì„ ìˆ˜ ìžˆìŒ
        - ëª¨ë¸ì˜ í™•ë¥ ì  íŠ¹ì„±ìƒ ìƒì„± ê²°ê³¼ê°€ ë§¤ë²ˆ ë‹¬ë¼ì§ˆ ìˆ˜ ìžˆì–´ ì‹ ë¢°ì„± ì €í•˜
    5. ìœ¤ë¦¬ì  ë¬¸ì œ
        - ì•…ìš© ê°€ëŠ¥ì„±ì´ ì¡´ìž¬í•˜ë©°, ì±…ìž„ ì†Œìž¬ íŒŒì•…ì´ ì–´ë ¤ìš¸ ìˆ˜ ìžˆìŒ
        - ëª¨ë¸ì˜ ì¶œë ¥ ê²°ê³¼ì— ëŒ€í•œ í†µì œì™€ ê²€ì¦ ì²´ê³„ ë§ˆë ¨ í•„ìš”
- ê°œì„ í•  ë‹¨ì 
    1. ì™¸ë¶€ ì§€ì‹ í™œìš© (ì´ ê²½ìš° íŠ¹ì • ë„ë©”ì¸ì˜ ë³´ì•ˆ ë“±ì˜ ë¬¸ì œë¡œ LLM ìžì²´ì— í•™ìŠµì‹œí‚¬ ìˆ˜ ì—†ëŠ” ë°ì´í„° í™œìš© ê°€ëŠ¥)
        - ëŒ€ê·œëª¨ì˜ êµ¬ì¡°í™”ëœ ì§€ì‹ ë² ì´ìŠ¤(ì˜ˆ: ìœ„í‚¤í”¼ë””ì•„)ë¥¼ ëª¨ë¸ì— ì—°ê²°
        - ì£¼ì–´ì§„ ì§ˆì˜ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ ë° ì¶”ì¶œ
    2. ì¦ê±° ê¸°ë°˜ ìƒì„±(ì™œ?)
        - ê²€ìƒ‰ëœ ì§€ì‹ ì •ë³´ë¥¼ ì¦ê±°ë¡œ í™œìš©í•˜ì—¬ ë³´ë‹¤ ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‹µë³€ ìƒì„±
        - ìƒì„±ëœ ë‹µë³€ì˜ ì¶œì²˜ë¥¼ ëª…ì‹œí•¨ìœ¼ë¡œì¨ ì‹ ë¢°ì„± í–¥ìƒ
    3. ë§¥ë½ ì´í•´ë ¥ í–¥ìƒ(ì™œ?)
        - ì™¸ë¶€ ì§€ì‹ì„ í†µí•´ ì§ˆì˜ì— ëŒ€í•œ ë°°ê²½ ì§€ì‹ê³¼ ë§¥ë½ ì •ë³´ë¥¼ íŒŒì•…
        - ë‹¨ìˆœí•œ íŒ¨í„´ ë§¤ì¹­ì´ ì•„ë‹Œ ì¶”ë¡  ëŠ¥ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ë‹µë³€ ìƒì„±

### **RAGì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œ**

1. Query Encoder : ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ì´í•´í•˜ê¸° ìœ„í•œ ëª¨ë¸ë¡œ, ì£¼ì–´ì§„ ì§ˆë¬¸ì„ ë²¡í„° í˜•íƒœë¡œ ì¸ì½”ë”©í•œë‹¤. BERTì™€ ê°™ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ì–´ í˜¹ì€ íŒ¨ì‹œì§€ë¥¼ ì¸ì½”ë”©í•œë‹¤.
2. Knowledge Retriever : ì¸ì½”ë”©ëœ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•œë‹¤. ê²€ìƒ‰ ê¸°ë°˜ ëª¨ë¸ì€ ì£¼ì–´ì§„  ì§ˆë¬¸ê³¼ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì˜ ê´€ë ¨ëœ ì •ë³´(ë°ì´í„°ë² ì´ìŠ¤ì˜ ë¬¸ìž¥)ì˜ ìœ ì‚¬ë„ë¥¼ ë¹„êµí•˜ì—¬ ë§¤ì¹˜í•œë‹¤.
    - ðŸ’¡ex)
        - ì§ˆë¬¸ : "What is the capital of France?â€
        - ë¬¸ì„œ(íŒ¨ì‹œì§€) ë°ì´í„°ë² ì´ìŠ¤ :
            
            íŒ¨ì‹œì§€ 1: "Paris is the capital and most populous city of France."
            
            íŒ¨ì‹œì§€ 2: "The Eiffel Tower is located in Paris."
            
            íŒ¨ì‹œì§€ 3: "Berlin is the capital of Germany
            
        
        ì§ˆë¬¸ê³¼ ë°ì´í„°ë² ì´ìŠ¤ì˜ íŒ¨ì‹œì§€ë¥¼ ì¸ì½”ë”©í•œë‹¤. RAGì˜ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ DRPì˜ ê²½ìš° word2vecì´ ì•„ë‹Œ ì „ì²´ ë¬¸ìž¥ì„ latent spaceë¡œ projectionì‹œì¼œ í•˜ë‚˜ì˜ ê³ ì°¨ì› ë²¡í„°ë¡œ ìž„ë² ë”©í•œë‹¤. ê·¸ í›„ ì§ˆë¬¸ê³¼ ë°ì´í„°ë² ì´ìŠ¤ì˜ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°(ì£¼ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„)ì„ í†µí•´ ê°€ìž¥ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ íŒ¨ì‹œì§€ë¥¼ ë°˜í™˜ í•œë‹¤.
        
        - ì¶œë ¥ : "Paris is the capital and most populous city of France.â€
        
3. Knowledge-Augmented Generator :  ì§ˆë¬¸ê³¼ Knowledge Retrieverì—ì„œ ì–»ì€ ìœ ì‚¬ë„ê°€ ë†’ì€ ì •ë³´ë¥¼ ê°™ì´ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•œë‹¤. ê²€ìƒ‰ëœ ì§€ì‹ì„ ì¶”ê°€ ìž…ë ¥ìœ¼ë¡œ ë°›ì•„ ê¸°ì¡´ì˜ LLMë³´ë‹¤ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìžˆë‹¤. RAG ë…¼ë¬¸ì—ì„œì˜ ê²½ìš°ëŠ” ì§ˆë¬¸ê³¼ retrieved contentë¥¼ concatenationí•˜ì˜€ë‹¤.

RAGëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì˜ ì •ë³´ë¥¼ ê²°í•©í•˜ì—¬ ìž…ë ¥ì„ ì¦ê°•ì‹œì¼œ ë³´ë‹¤ ì •í™•í•˜ê³  , ì¶œë ¥ ê²°ê³¼ì— ëŒ€í•œ ì™¸ë¶€ë°ì´í„°ì˜ ê·¼ê±°ë¥¼ ì œì‹œ í•  ìˆ˜ ìžˆì–´ ì„¤ëª… ê°€ëŠ¥ì„±ê³¼ ì‹ ë¢°ì„±ì„ ë†’ì¼ ìˆ˜ ìžˆë‹¤.

RAG ê¸°ìˆ ì€ ì •ë³´ ê²€ìƒ‰, íŒ©íŠ¸ ì²´í‚¹, ì§ˆì˜ì‘ë‹µ, ë“±ì˜ taskì—ì„œ í™œë°œížˆ ì—°êµ¬ë˜ê³  ìžˆë‹¤. í•œê³„ì ìœ¼ë¡œëŠ” ì—°ê²°ëœ ì§€ì‹ ë² ì´ìŠ¤ì— ì˜ì¡´í•˜ë¯€ë¡œ, ì—°ê²°ëœ ì§€ì‹ ë² ì´ìŠ¤ì˜ ê´€ë¦¬ì™€ í’ˆì§ˆê³¼ ì»¤ë²„ë¦¬ì§€ë¥¼ í–¥ìƒ ì‹œí‚¤ê¸° ìœ„í•œ ê¸°ë²•ì— ëŒ€í•œ ì—°êµ¬ê°€ ì¤‘ìš”í•œ ê³¼ì œë¡œ ë‚¨ì•„ìžˆë‹¤.

- ðŸ’¡ê°œì¸ ì˜ê²¬
    
    ê³¼ì œì— ì°¸ì—¬ëœ ê° ë„ë©”ì¸ì˜ ì§€ì‹ë² ì´ìŠ¤ë¥¼ ì´ìš©í•˜ì—¬ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì„ ë§Œë“œëŠ” ê²ƒë„ ê³ ë ¤í•´ ë³¼ ìˆ˜ ìžˆì„ ê²ƒ ê°™ë‹¤.
    

## LLM í’ˆì§ˆ í‰ê°€ ê¸°ìˆ 

Machine Translationí‰ê°€ ì§€í‘œë“¤

![image.png](RAGëž€ ,RAG í‰ê°€ì§€í‘œ.assets/image.png)

Taxonomy of automatic evaluation metrics. [(ê·¸ë¦¼ ì¶œì²˜,A Survey on Evaluation Metrics for Machine Translation)](https://www.mdpi.com/2227-7390/11/4/1006)

[Ref 1](https://blog.testworks.co.kr/ai_llm_evaluation_1/) , [Ref 2](https://blog.testworks.co.kr/ai_llm_evaluation_2/)
**BLEU (BiLingual Evaluation Understudy Score)**

ì´ˆê¸°ì—ëŠ” ê¸°ê³„ ë²ˆì—­ì—ì„œ í’ˆì§ˆì„ í‰ê°€í•˜ê¸° ìœ„í•´ ê°œë°œë˜ì—ˆìœ¼ë‚˜, í˜„ìž¬ëŠ” í™œìš© ë²”ìœ„ê°€ í™•ìž¥ë˜ì–´ ë²ˆì—­ ë¿ ë§Œ ì•„ë‹ˆë¼ ì •ë‹µ ë¬¸ìž¥ê³¼ ë¹„êµë¥¼ í•˜ê¸° ìœ„í•´ì„œë„ ì‚¬ìš©ëœë‹¤. ì–¸ì–´ ëª¨ë¸ì˜ ì¶œë ¥ì´ ì‚¬ëžŒì´ ìž‘ì„±í•œ í…ìŠ¤íŠ¸ì— ì–¼ë§ˆë‚˜ ê°€ê¹Œìš´ ì§€ë¥¼ í‰ê°€í•œë‹¤. BLEU ì ìˆ˜ëŠ” 0ì—ì„œ 1ê¹Œì§€ì´ë©°, ì ìˆ˜ê°€ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì‚¬ëžŒì´ ìž‘ì„±í•œ ì°¸ì¡° ë²ˆì—­ê³¼ ìœ ì‚¬ì„±ì´ ë†’ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. BLEUì˜ n-gramì˜ precisionì€ ì•„ëž˜ì˜ ì‹ê³¼ ê°™ì´ ì •ì˜ ëœë‹¤.

$p_n = \frac{the\ number\ of\ N-gram\ which\ occur\ in\ any\ Reference}{the\ total\ number\ of\ N-gram\ in\ candidate}$

- ðŸ’¡n-gramì´ëž€?
    
    **n**ê°œì˜ ì—°ì†ëœ ë‹¨ì–´ ë˜ëŠ” í† í°ì˜ ì‹œí€€ìŠ¤
    ex) â€œThe cat satâ€
    
    1-gram(Unigram) : ["The", "cat", "sat"]
    2- gram(Bigram) : ["The cat", "cat sat"]
    
    3-gram(Trigram) : ["The cat sat"]
    

n-gramì—ì„œ nì˜ ê°’ì„ 1~4ë“±ìœ¼ë¡œ í•˜ì—¬ ê°ê°ì˜ n-gramì— ëŒ€í•˜ì—¬ ì ìˆ˜ë¥¼ ê³„ì‚°í•œ í›„ í‰ê· ê°’ì„ ì‚¬ìš©í•œë‹¤. N ë§ˆë‹¤ ê°€ì¤‘ì¹˜ë‚˜ íŒ¨ë„í‹°ë¥¼ ì„¤ì •í•˜ì—¬ BLEUë¥¼ ê³„ì‚°í•˜ê¸°ë„ í•œë‹¤.

ì´ë•Œ íŒ¨ë„í‹°ë¥¼ ì£¼ëŠ” ê¸°ë²•ìœ¼ë¡œ Brevity Penaltyì´ ìžˆë‹¤. ìƒì„±ëœ ë¬¸ìž¥ì˜ ê¸¸ì´ë¥¼ c, ì •ë‹µ ë¬¸ìž¥ì˜ ê¸¸ì´ë¥¼ r ì´ë¼ê³  í•œë‹¤ë©´ Brevity PenaltyëŠ” ì•„ëž˜ì˜ ì‹ê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤.

$$
BP = \begin{cases} 1, &\text{if } c>r\\ e^{(1-r/c)}, &\text{if } c<=r\end{cases}
$$

BLEUëŠ” ìµœì¢…ì ìœ¼ë¡œ ë‹¤ìŒ ì‹ê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤.

$$
BLEU = BP\cdot exp(\displaystyle\sum_{i=1}^n w_n log p_n)
$$

BLUEëŠ” ê°„ë‹¨í•˜ê³  ì§ê´€ì ì¸ ê³„ì‚° ë°©ë²• ë•Œë¬¸ì— ë„ë¦¬ ì‚¬ìš©ë˜ë‚˜ ì°¸ì¡° ë²ˆì—­ì˜ í’ˆì§ˆì— ì˜í–¥ì„ ë°›ê³  ê³„ì‚° ìˆ˜ì‹ì´ n-gramì˜  ì¼ì¹˜ë„ë§Œ ê³ ë ¤í•˜ê¸° ë•Œë¬¸ì—  ë¬¸ë§¥,ë¬¸ìž¥ì˜ ì˜ë¯¸, ë¬¸ë²•ì  êµ¬ì¡°ë¥¼ ì œëŒ€ë¡œ ë°˜ì˜í•˜ì§€ ëª»í•œë‹¤ëŠ” í•œê³„ì ì´ ìžˆë‹¤. 

**METEOR (Metric for Evaluation of Translation with Explicit ORdering)**

BLEUëŠ” ê°€ìž¥ ëŒ€ì¤‘ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í‰ê°€ ì§€í‘œ ì¤‘ í•˜ë‚˜ì´ì§€ë§Œ, í•œê³„ì ì´ ì¡´ìž¬í•œë‹¤. BLEUì˜ ë‹¨ì ì„ ê·¹ë³µí•˜ì—¬ ë¬¸ìž¥ì˜ ì§ˆì„ í‰ê°€í•˜ê¸° ìœ„í•´ METEORë¼ëŠ” í‰ê°€ ê¸°ë²•ì´ ì œì‹œ ë˜ì—ˆë‹¤. METEORì€ unigram ë‹¨ìœ„ì—ì„œì˜ recallê³¼ precisionì˜ ì¡°í™”í‰ê· ê°’ì„ êµ¬í•œë‹¤.

- ðŸ’¡ì¡°í™” í‰ê· ì´ëž€
    
    ì¡°í™”í‰ê· ì€ 'ì—­ìˆ˜ì˜ ì‚°ìˆ í‰ê· ì˜ ì—­ìˆ˜'ì´ë‹¤. ì—­ìˆ˜ì˜ ì°¨ì›ì—ì„œ í‰ê· ì„ êµ¬í•˜ê³ , ë‹¤ì‹œ ì—­ìˆ˜ë¥¼ ì·¨í•´ ì›ëž˜ ì°¨ì›ì˜ ê°’ìœ¼ë¡œ ëŒì•„ì˜¤ëŠ” ê²ƒì´ë‹¤. 
    
    ex) ê°ˆ ë•Œ 10m/s, ì˜¬ë•Œ 20m/s ë¡œ ì£¼í–‰í•˜ì˜€ë‹¤. í‰ê·  ì†ë ¥ì€?
    
    10ê³¼ 20ì˜ ì‚°ìˆ  í‰ê· ì¸ 15ëŠ” ë‹µì´ ì•„ë‹ˆë‹¤. ê°ˆ ë•Œì™€ ì˜¬ ë•Œ íˆ¬ì—¬í•œ ì‹œê°„ì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì´ë‹¤. ì—¬ê¸°ì„œëŠ” ì‹œê°„ì˜ ì°¨ì›ì—ì„œ í‰ê· ì„ êµ¬í•´ì•¼ í•œë‹¤. ê±°ë¦¬ë¥¼ ì†ë ¥ìœ¼ë¡œ ë‚˜ëˆ„ë©´(ì—­ìˆ˜), ì‹œê°„ì¸ë°, ì´Â **ì‹œê°„ì˜ í‰ê· **ì„ êµ¬í•œ í›„ì—, êµ¬í•œ ì‹œê°„ ê°’ì— ëŒ€í•´, ë‹¤ì‹œ ì†ë ¥ìœ¼ë¡œ ë°”ê¾¼ ê²ƒì´ í‰ê·  ì†ë ¥ì´ë‹¤.
    ê±°ë¦¬ë¥¼ Së¼ í•˜ê³ , ì‹œê°„ì— ëŒ€í•´ ì‹ì„ ì„¸ìš°ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
    
    $$
    \frac{S}{10} + \frac{S}{20} = \frac{2S}{x}
    $$
    
    ì´ë•Œ $x = \frac{40}{3}$ ì´ ëœë‹¤.ì´ ì˜ˆì œë¥¼ ì¼ë°˜í™”í•˜ì—¬,  ê°ˆ ë•Œ ì†ë ¥ì„ a, ì˜¬ ë•Œ ì†ë ¥ì„ bë¼ í•˜ì—¬ ì •ë¦¬í•˜ë©´, ì¡°í™”í‰ê· ì€ ë‹¤ìŒ ì‹ê³¼ ê°™ì´ ëœë‹¤.
    
    $$
    x = \frac{2ab}{a+b}
    $$
    

recallê³¼ precisionì— 1:9ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ë‘ê³  ì¡°í™” í‰ê· ì„ êµ¬í•˜ë©° ì•„ëž˜ ì‹ê³¼ ê°™ì´ ì¡°í™” í‰ê· ì„ ê³„ì‚°í•œë‹¤.

$$
F_{mean} = \frac{10PR}{R+9P}
$$

$$
METEOR = F_{mean}(1-0.5(\frac{c}{u_m})^3)
$$

**GLUE (General Language Understanding Evaluation)**

2019ë…„ BERT paperê°€ ë°œí‘œë˜ë©´ì„œ ë“±ìž¥í•œ í‰ê°€ì§€í‘œì´ë‹¤. ìžì—°ì–´ ì´í•´(NLU) íƒœìŠ¤í¬ë¥¼ ëª¨ì•„ë†“ì€ ë²¤ì¹˜ë§ˆí¬ì´ë‹¤. í¬í•¨ëœ ë²¤ì¹˜ë§ˆí¬ëŠ” ì•„ëž˜ì™€ ê°™ë‹¤.

- GLUEì— í¬í•¨ëœ ë²¤ì¹˜ë§ˆí¬
    - Quora Question Pairs (QQP, ë¬¸ìž¥ ìœ ì‚¬ë„ í‰ê°€)
    - Question NLI (QNLI, ìžì—°ì–´ ì¶”ë¡ )
    - The Stanford Sentiment Treebank (SST, ê°ì„± ë¶„ì„)
    - The Corpus of Linguistic Acceptability (CoLA, ì–¸ì–´ ìˆ˜ìš©ì„±)
    - Semantic Textual Simiilarity Benchmark (STS-B, ë¬¸ìž¥ ìœ ì‚¬ë„ í‰ê°€)
    - Microsoft Research Paraphrase Corpus (MRPC, ë¬¸ìž¥ ìœ ì‚¬ë„ í‰ê°€)
    - Recognizing Textual Entailment (RTE, ìžì—°ì–´ ì¶”ë¡ )
    - SQUAD 1.1 / 2.0 (ì§ˆì˜ì‘ë‹µ)
    - MultiNLI Matched (ìžì—°ì–´ ì¶”ë¡ )
    - MultiNLI Mismatched (ìžì—°ì–´ ì¶”ë¡ )
    - Winograd NLI (ìžì—°ì–´ ì¶”ë¡ )

ìžì—°ì–´ ì´í•´ ëª¨ë¸ì„ ìœ„í•œ í‰ê°€ ì§€í‘œë¡œ ì£¼ë¡œ ì‚¬ìš©ë˜ì§€ë§Œ ìžì—°ì–´ ìƒì„± ëª¨ë¸ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ì§€í‘œì— í¬í•¨ë˜ê¸°ë„ í•œë‹¤. GLUEëŠ” ì˜ì–´ì—ë§Œ ì ìš©ë˜ëŠ” í‰ê°€ ì§€í‘œì´ê¸° ë•Œë¬¸ì— ê° ì–¸ì–´ì— ë”°ë¼ KLUE(í•œêµ­ì–´), CLUE(ì¤‘êµ­ì–´)

- ðŸ’¡ê°œì¸ ìƒê°
    
    KLUE, CLUE ì²˜ëŸ¼ ì˜ë£Œ, ë²•ë¥ , ì œì¡°, ë¯¸ë””ì–´ ê°ê°ì„ ìœ„í•œ í‰ê°€ì§€í‘œë‚˜ ë°ì´í„°ì…‹ êµ¬ì¶• ì‹œë„ë„ í•  ìˆ˜ ìžˆì„ ê²ƒìœ¼ë¡œ ë³´ìž„.
    

**CIDEr (Consensus-based Image Description Evaluation)**

CIDErì€ TF-IDF( Term Frequency-Inverse Document Frequency)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œë‹¤. TF(ë‹¨ì–´ ë¹ˆë„) â€˜í•œ ë¬¸ìž¥ ì•ˆì— ê°™ì€ ë‹¨ì–´ê°€ ì—¬ëŸ¬ ë²ˆ ë“±ìž¥í•  ê²½ìš° ì¤‘ìš”ì„±ì´ ë†’ì„ ê°€ëŠ¥ì„±ì´ í¬ë‹¤â€™ ë¥¼ ê°€ì •í•˜ì—¬, í•´ë‹¹ n-gramì´ ì •ë‹µ ë¬¸ìž¥ ê°ê°ì—ì„œ ëª‡ ë²ˆì´ë‚˜ ë“±ìž¥ í–ˆëŠ”ì§€ë¥¼ ë³¸ë‹¤. ID(Inverse Document Frequency)ëŠ” ì •ë‹µ ë¬¸ìž¥ ì¤‘ ëª‡ êµ°ë°ì—ì„œë‚˜ í•´ë‹¹ n-gramì´ ë“±ìž¥í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” DFì— ì—­ìˆ˜ì™€ logë¥¼ ìˆœì„œëŒ€ë¡œ ì·¨í•œ ê°’ì´ë‹¤. â€˜íŠ¹ì • ë‹¨ì–´ê°€ ì—¬ëŸ¬ ë¬¸ì„œ(ì‚¬ì§„)ì—ì„œ ê³µí†µì ìœ¼ë¡œ ë°œê²¬ëœë‹¤ë©´ ì˜¤ížˆë ¤ í•µì‹¬ì´ ë˜ëŠ” ë‹¨ì–´ê°€ ì•„ë‹ˆë‹¤â€™ ë¥¼ ê°€ì •í•˜ì—¬ ì—­ìˆ˜ë¥¼ ì·¨í•œë‹¤.

ì´ TF-IDF ê°’ì„ ìƒì„±ëœ ë¬¸ìž¥ê³¼ ì •ë‹µ ë¬¸ìž¥ì—ì„œ n-gram(1â‰¤nâ‰¤4)ì— ëŒ€í•´ ì‹¤ì‹œí•œ í›„, ê·¸ ê°’ì„ ë²¡í„°ë¡œ ë‚˜íƒ€ë‚¸ë‹¤. ì •ë‹µ ë¬¸ìž¥ê³¼ ìƒì„±ëœ ë¬¸ìž¥ ë²¡í„°ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ êµ¬í•˜ê³  ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ í‰ê· ì„ ë‚´ì„œ CIDEr ì ìˆ˜ë¥¼ ê³„ì‚°í•œë‹¤.

**SPICE (Semantic Propositional Image Caption Evaluation)**

SPICE (Semantic Propositional Image Caption Evaluation)ì€ ì§€ê¸ˆê¹Œì§€ì˜ í‰ê°€ì§€í‘œì™€ëŠ” ë‹¤ë¥´ê²Œ n-gramì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” í‰ê°€ ì§€í‘œìž…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì •ë‹µ ë¬¸ìž¥ì´ ì—¬ëŸ¬ ê°œ ìžˆëŠ” ê²ƒì— ì°©ì•ˆí•˜ì—¬, ì •ë‹µ ë¬¸ìž¥ë“¤ì˜ ë‹¨ì–´ë“¤ì„ Object, Attribute Relationìœ¼ë¡œ êµ¬ë¶„í•˜ê³  ì´ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê·¸ëž˜í”„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.

**MMLU (Massive Multitask Language Understanding)**

MMLUëŠ” ëª¨ë¸ì´ ì‚¬ì „ í•™ìŠµ ë™ì•ˆ ë‚´ìž¬í•œ ì§€ì‹ì„ í‰ê°€í•˜ë ¤ëŠ” ëª©ì ì„ ê°€ì§€ê³  ê°œë°œë˜ì—ˆë‹¤. STEM, ì¸ë¬¸í•™, ì‚¬íšŒ ê³¼í•™ ë“± 57ê°œì˜ ê³¼ëª©ì„ ë‹¤ë£¨ë©° ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì§ˆë¬¸ë“¤ì´ ëª¨ì—¬ ìžˆë‹¤. ëª¨ë¸ì€ ì§ˆë¬¸ì´ë‚˜ ì§€ë¬¸ì„ ì½ê³ , 4ê°œì˜ ì„ íƒì§€ ì¤‘ ì í•©í•œ ê²ƒì„ ê³ ë¥´ê³  ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¸ì„ í‰ê°€í•œë‹¤. ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ê³¼ëª©ì„ í¬í•¨í•˜ê³  ìžˆì–´ ëª¨ë¸ì˜ ì•½ì ì„ íŒŒì•…í•˜ëŠ”ë° ì‚¬ìš©í•œë‹¤.

**BIG-Bench**

2022ë…„ì— êµ¬ê¸€ì—ì„œ ì£¼ê´€í•˜ì—¬ êµ¬ì¶•í•œ ë²¤ì¹˜ë§ˆí¬ë¡œ BIG(Beyond the Imitation Game)-BenchëŠ” 200ê°œê°€ ë„˜ëŠ” ìœ í˜•ì˜ ë¬¸ì œë“¤ë¡œ êµ¬ì„±ëœ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì´ë‹¤. ì´ ì¤‘ì—ì„œ í‰ê· ì ì¸ ì‚¬ëžŒì˜ ì ìˆ˜ë¥¼ ë„˜ì§€ ëª»í•œ ìœ í˜•ì„ ë”°ë¡œ ë¬¶ì–´ BBH(Big-Bench-Hard)ë¼ê³  ë¶€ë¥´ê¸°ë„ í•œë‹¤.

ë‹¨ìˆœí•œ í‰ê°€ë¥¼ ë„˜ì–´ ê³µê°œì ìœ¼ë¡œ ë¦¬ë”ë³´ë“œë¥¼ ì—´ì–´ ê²½ìŸì„ ìœ ë„í•˜ëŠ” ê²½ìš°ë„ ìžˆìŠµë‹ˆë‹¤. AIhub í™ˆíŽ˜ì´ì§€ì— ê³µê°œë˜ì–´ ìžˆëŠ” Open Ko-LLM Leaderboard (Â [https://www.aihub.or.kr/leaderboard/view.do](https://www.aihub.or.kr/leaderboard/view.do)Â )ê°€ ëŒ€í‘œì ì¸ ì˜ˆìž…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ëª¨ë¸ì„ ì´ ë‹¤ì„¯ê°€ì§€ ë¶„ì•¼(ì¶”ë¡ ëŠ¥ë ¥, ìƒì‹ëŠ¥ë ¥, ì–¸ì–´ì´í•´ë ¥, í™˜ê°ë°©ì§€ëŠ¥ë ¥, í•œêµ­ì–´ ìƒì‹ìƒì„±ëŠ¥ë ¥)ì— ëŒ€í•´ì„œ í‰ê°€í•˜ê³ , ê·¸ ì„±ì ì„ ìˆœìœ„í‘œì— ê¸°ë¡í•©ë‹ˆë‹¤.

**ì„œë¹„ìŠ¤ ìˆ˜ì¤€ì—ì„œ í‰ê°€í•˜ëŠ” ë°©ë²•ê³¼, ê·¸ ë°©ë²•ì„ ë§ˆë ¨í•˜ëŠ” ê¸°ì¤€**

ì•žì„œ ì–¸ê¸‰í•œ ê¸°ë³¸ì ì¸ ì–¸ì–´ ëŠ¥ë ¥ì„ ë³´ì§€ë§Œ ë²¤ì¹˜ë§ˆí¬ í‰ê°€ì—ì„œëŠ” ì‹¤ì œë¡œ ëª¨ë¸ì´ ìƒì„±í•˜ì§€ ì•Šê¸°ë„ í–ˆê³ , ê¸°ê³„ì ì¸ í‰ê°€ëŠ” ì ìˆ˜ê°€  ë†’ì•„ë„ ì‚¬ëžŒì´ ë³´ê¸°ì— ë§Œì¡±ìŠ¤ëŸ½ì§€ëŠ” ì•Šì„ ìˆ˜ ìžˆë‹¤ëŠ” í•œê³„ì ì´ìžˆë‹¤. ê·¸ëž˜ì„œ ê³µí†µì ìœ¼ë¡œ ìƒì„±ëœ ë¬¸ìž¥ì˜ ì–¸ì–´ì  ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ì§€í‘œë¡œ ì •í™•ì„±, ìœ ì°½ì„±, ì¼ê´€ì„±ì„ ì‚¬ìš©í•œë‹¤. 

ì •í™•ì„± í‰ê°€ì—ì„œëŠ” ëª¨ë¸ì— ì§€ì‹œí•œ ë‚´ìš©ì´ ì •í™•í•˜ê²Œ ìˆ˜í–‰ë˜ì—ˆëŠ”ì§€, ì§ˆë¬¸ì„ í•œ ê²½ìš° ëŒ€ë‹µì— ê±°ì§“ì´ ìžˆì§€ëŠ” ì•Šì€ì§€  í‰ê°€í•œë‹¤. ìœ ì°½ì„± í‰ê°€ì—ì„œëŠ” ìƒì„±ëœ ë¬¸ìž¥ì— ë¬¸ë²•ì ì¸ ì˜¤ë¥˜ëŠ” ì—†ëŠ”ì§€, ì–´ìƒ‰í•œ í‘œí˜„ì€ ì—†ëŠ”ì§€ë¥¼ í‰ê°€í•œë‹¤. ì¼ê´€ì„± í‰ê°€ì—ì„œëŠ” ìƒì„±ëœ ë‹µë³€ì— ìžê¸°ëª¨ìˆœì ì¸ ë‚´ìš©ì€ ì—†ëŠ”ì§€, í˜¹ì€ ë§íˆ¬ê°€ ë¹„ìŠ·í•˜ê²Œ ìœ ì§€ë˜ëŠ”ì§€ ë“±ì„ í‰ê°€í•œë‹¤.

- ðŸ’¡ê°œì¸ ìƒê°
    
    ìœ„ì˜ ë‚´ìš© ì™¸ì—ë„ ë§Žìœ¼ë‚˜ ê¸°ê³„ ë²ˆì—­ taskì—ì„œì˜ ë‚´ìš©ì´ ì£¼ë¥¼ ì´ë£¨ê¸°ì— ìžë£Œ ì¡°ì‚¬ ì¤‘ë‹¨í•˜ê³  RAG í‰ê°€ì§€í‘œë¥¼ ì¡°ì‚¬. ê¸°ê³„ë²ˆì—­ì„ ìœ„í•œ í‰ê°€ì§€í‘œë“¤ì´ ë¼ëŠ” ê²ƒì„ ëŠ¦ê²Œ ì•Œì•˜ê³  LLMì€ NLU(ìžì—°ì–´ ì´í•´), NLG(ìžì—°ì–´ ìƒì„±), QA(ì§ˆë¬¸ ì‘ë‹µ)ë“± ì— ëŒ€í•œ í‰ê°€ì§€í‘œê°€ ë” ì¤‘ìš”í•¨. LLMì„ ìœ„í•œ ëŒ€í‘œì  í‰ê°€ì§€í‘œ ëª‡ê°€ì§€ë§Œ ì¶”ë ¤ì•¼ ë  ê²ƒ ê°™ìŒ
    

## RAG ì„±ëŠ¥ í‰ê°€ ê¸°ìˆ 

rag paperì—ì„œëŠ” Open-domain Question Answering, Abstractive Question Answering, Jeopardy Question Generation, Fact Verificationì„ í‰ê°€ ì§€í‘œë¡œ ì‚¬ìš©í•¨

- ðŸ’¡ ê°œì¸ìƒê°
    
    gold passageì™€ ëª¨ë¸ì˜ ìž„ë² ë”© ì •ë³´ì˜ mean_distë‚˜ triplet_loss ë°©ì‹ìœ¼ë¡œ ìž„ë² ë”©ì˜ ìœ ì‚¬ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œ í™œìš© ê°€ëŠ¥í•´ ë³´ìž„
